{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification using the one-dimensional Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Wine** data set is the running example for our discussion of the *generative approach to classification*. \n",
    "\n",
    "The data can be downloaded from the UCI repository (https://archive.ics.uci.edu/ml/datasets/wine). It contains 178 labeled data points, each corresponding to a bottle of wine:\n",
    "* The features (`x`): a 13-dimensional vector consisting of visual and chemical features for the bottle of wine\n",
    "* The label (`y`): the winery from which the bottle came (1,2,3)\n",
    "\n",
    "Before continuing, download the data set and place it in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "# installing packages for interactive graphs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the Wine data set. There are 178 data points, each with 13 features and a label (1,2,3).\n",
    "We will divide these into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wine.data.txt' needs to be in the same directory\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix a particular \"random\" permutation of the data, and use these to effect the training / test split.\n",
    "We get four arrays:\n",
    "* `trainx`: 130x13, the training points\n",
    "* `trainy`: 130x1, labels of the training points\n",
    "* `testx`: 48x13, the test points\n",
    "* `testy`: 48x1, labels of the test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "# Also split apart data and labels\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many training points there are from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 54, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trainy==1), sum(trainy==2), sum(trainy==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you figure out how many test points there are from each class? *Note down these three numbers: you will enter it as part of this week's programming assignment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 17, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify this cell\n",
    "sum(testy==1), sum(testy==2), sum(testy==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Look at the distribution of a single feature from one of the wineries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick just one feature: 'Alcohol'. This is the first feature, that is, number 0. Here is a *histogram* of this feature's values under class 1, along with the *Gaussian fit* to this distribution.\n",
    "\n",
    "<img src=\"histogram.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm: how can we generate a figure like this? \n",
    "\n",
    "The following function, **density_plot**, does this for any feature and label. The first line adds an interactive component that lets you choose these parameters using sliders. \n",
    "\n",
    "<font color=\"magenta\">Try it out!</font> And then, look at the code carefully to understand exactly what it is doing, line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe29422cdf0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trainx[trainy==1, 1], density=True)\n",
    "mu = np.mean(trainx[trainy==1,1]) # mean\n",
    "var = np.var(trainx[trainy==1,1]) # variance\n",
    "std = np.sqrt(var) # standard deviation\n",
    "x_axis = np.linspace(mu - 3*std, mu + 3*std, 1000)\n",
    "plt.plot(x_axis, norm.pdf(x_axis,mu,std), 'r', lw=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd565474ec94a7996074840ea830975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature', max=12), IntSlider(value=1, description='label…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12), label=IntSlider(1,1,3))\n",
    "def density_plot(feature, label):\n",
    "    plt.hist(trainx[trainy==label,feature], density=True)\n",
    "    #\n",
    "    mu = np.mean(trainx[trainy==label,feature]) # mean\n",
    "    var = np.var(trainx[trainy==label,feature]) # variance\n",
    "    std = np.sqrt(var) # standard deviation\n",
    "    #\n",
    "    x_axis = np.linspace(mu - 3*std, mu + 3*std, 1000)\n",
    "    plt.plot(x_axis, norm.pdf(x_axis,mu,std), 'r', lw=2)\n",
    "    plt.title(\"Winery \"+str(label) )\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function **density_plot**, the code for plotting the Gaussian density focuses on the region within 3 standard deviations of the mean. Do you see where this happens? Why do you think we make this choice?\n",
    "\n",
    "Here's something for you to figure out: for which feature (0-12) does the distribution of (training set) values for winery 1 have the *smallest* standard deviation? Write down the answer: you will need to enter it as part of this week's programming assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify this cell\n",
    "std = np.zeros(13)\n",
    "for feature in range(0,13):\n",
    "    std[feature] = np.std(trainx[trainy==1,feature])\n",
    "np.argmin(std) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit a Gaussian to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that will fit a Gaussian generative model to the three classes, restricted to just a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes y takes on values 1,2,3\n",
    "def fit_generative_model(x,y,feature):\n",
    "    k = 3 # number of classes\n",
    "    mu = np.zeros(k+1) # list of means\n",
    "    var = np.zeros(k+1) # list of variances\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label] = np.mean(x[indices,feature])\n",
    "        var[label] = np.var(x[indices,feature])\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, var, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function on the feature 'alcohol'. What are the class weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33076923 0.41538462 0.25384615]\n"
     ]
    }
   ],
   "source": [
    "feature = 0 # 'alcohol'\n",
    "mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "print(pi[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, display the Gaussian distribution for each of the three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831ce4d2144f49e990eaf0c706b8ae8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature', max=12), Button(description='Run Interact', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12) )\n",
    "def show_densities(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        m = mu[label]\n",
    "        s = np.sqrt(var[label])\n",
    "        x_axis = np.linspace(m - 3*s, m+3*s, 1000)\n",
    "        plt.plot(x_axis, norm.pdf(x_axis,m,s), colors[label-1], label=\"class \" + str(label))\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the widget above to look at the three class densities for each of the 13 features. Here are some questions for you:\n",
    "* For which feature (0-12) do the densities for classes 1 and 3 *overlap* the most?\n",
    "* For which feature (0-12) is class 3 the most spread out relative to the other two classes?\n",
    "* For which feature (0-12) do the three classes seem the most *separated* (this is somewhat subjective at present)?\n",
    "\n",
    "*Write down the answers to these questions: you will enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict labels for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well can we predict the class (1,2,3) based just on one feature? The code below lets us find this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b5a006ece04c7db8e38ca786440275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature', max=12), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( feature=IntSlider(0,0,12) )\n",
    "def test_model(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "\n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    n_test = len(testy) # Number of test points\n",
    "    score = np.zeros((n_test,k+1))\n",
    "    for i in range(0,n_test):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            norm.logpdf(testx[i,feature], mu[label], np.sqrt(var[label]))\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    print(\"Test error using feature \" + featurenames[feature] + \": \" + str(errors) + \"/\" + str(n_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">One last exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are looking at classifiers that use just one out of a possible 13 features. Choosing a subset of features is called **feature selection**. In general, this is something we would need to do based solely on the *training set*--that is, without peeking at the *test set*.\n",
    "\n",
    "For the wine data, compute the training error and test error associated with each choice of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 0\n",
      "49 1\n",
      "66 2\n",
      "68 3\n",
      "61 4\n",
      "46 5\n",
      "27 6\n",
      "55 7\n",
      "60 8\n",
      "38 9\n",
      "48 10\n",
      "47 11\n",
      "35 12\n",
      "####\n",
      "17 0\n",
      "23 1\n",
      "29 2\n",
      "23 3\n",
      "21 4\n",
      "16 5\n",
      "8 6\n",
      "23 7\n",
      "16 8\n",
      "10 9\n",
      "14 10\n",
      "19 11\n",
      "17 12\n"
     ]
    }
   ],
   "source": [
    "### Write your code here\n",
    "def training_error(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    n_train = len(trainy) # Number of training points\n",
    "    score = np.zeros((n_train,k+1))\n",
    "    for i in range(0,n_train):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            norm.logpdf(trainx[i,feature], mu[label], np.sqrt(var[label]))\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != trainy)\n",
    "    # print(\"Test error using feature \" + featurenames[feature] + \": \" + str(errors) + \"/\" + str(n_train))\n",
    "    return errors\n",
    "\n",
    "def test_error(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    n_test = len(testy) # Number of testing points\n",
    "    score = np.zeros((n_test,k+1))\n",
    "    for i in range(0,n_test):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            norm.logpdf(testx[i,feature], mu[label], np.sqrt(var[label]))\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    return errors\n",
    "\n",
    "for i in range(0,13):\n",
    "    print(training_error(i), i)\n",
    "print('####')\n",
    "for i in range(0,13):\n",
    "    print(test_error(i), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your findings, answer the following questions:\n",
    "* Which three features have the lowest training error? List them in order (best first).\n",
    "* Which three features have the lowest test error? List them in order (best first).\n",
    "\n",
    "*Note down your answers: you will enter them later, as part of this week's programming assignment*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "vscode": {
   "interpreter": {
    "hash": "73df3d2a648ddfe6e132dd0b2981f8c5ee01eb57f65aaa52301d101a94b0ebb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
